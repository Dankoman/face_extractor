#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ArcFace-pipeline med progressbar & checkpoints.

- L√§ser data_root/person/*.jpg|png|...
- Detekterar ansikten med InsightFace (SCRFD), ber√§knar embeddings (ArcFace)
- Upsamplar sm√• bilder innan detektion (valbart)
- Fallback: om ingen detektion -> direkt embedding p√• 112x112 (valbart)
- Sparar embeddings + etiketter i embeddings.pkl
- Tr√§nar KNN (cosine) och sparar modell i face_knn_arcface.pkl
- Checkpoints: processed.jsonl + embeddings.pkl s√• du kan avbryta/forts√§tta

Exempel:
  python face_arc_pipeline.py --mode both --data-root /home/marqs/Bilder/pr0n/Faces
"""

import sys
import json
import pickle
import argparse
from pathlib import Path
from typing import List, Tuple, Optional

import numpy as np
from PIL import Image
from tqdm.auto import tqdm
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier

from insightface.app import FaceAnalysis

# ------------------ Default ------------------
DEFAULT_DATA_ROOT   = "/home/marqs/Bilder/pBook"
DEFAULT_WORKDIR     = "./arcface_work"
EMB_PKL             = "embeddings_new.pkl"
PROC_JSONL          = "processed.jsonl"
MODEL_PKL           = "face_knn_arcface_new.pkl"

MIN_WIDTH           = 40
MIN_HEIGHT          = 40
UPSAMPLE_TARGET_MIN = 180   # minsta sida efter upsampling-f√∂rs√∂k

K_DEFAULT           = 3
MIN_PER_CLASS_DEF   = 2
# ---------------------------------------------


# -------------- Hj√§lpfunktioner --------------
def init_app(providers: List[str]) -> FaceAnalysis:
    app = FaceAnalysis(name="buffalo_l", providers=providers)
    app.prepare(ctx_id=0)
    return app

def load_processed(proc_path: Path) -> set:
    done = set()
    if proc_path.exists():
        with proc_path.open("r", encoding="utf-8") as f:
            for line in f:
                try:
                    rec = json.loads(line)
                    done.add(rec["path"])
                except Exception:
                    pass
    return done

def append_processed(proc_path: Path, img_path: str, ok: bool) -> None:
    with proc_path.open("a", encoding="utf-8") as f:
        f.write(json.dumps({"path": img_path, "ok": ok}) + "\n")

def load_embeddings(emb_path: Path) -> Tuple[List[np.ndarray], List[str]]:
    if not emb_path.exists():
        return [], []
    with emb_path.open("rb") as f:
        data = pickle.load(f)
    return data["X"], data["y"]

def save_embeddings(emb_path: Path, X, y):
    """Sparar embeddings till en tempor√§r fil och byter namn."""
    emb_path = Path(emb_path)  # Se till att emb_path √§r en Path-objekt
    emb_path.parent.mkdir(parents=True, exist_ok=True)  # Skapa mappen om den inte finns

    tmp = emb_path.with_suffix(".tmp")
    with tmp.open("wb") as f:
        pickle.dump({"X": X, "y": y}, f)
    tmp.rename(emb_path)

def iter_images(root: Path):
    exts = {".jpg", ".jpeg", ".png", ".bmp"}
    for person_dir in root.iterdir():
        if not person_dir.is_dir():
            continue
        label = person_dir.name
        for p in person_dir.iterdir():
            if p.suffix.lower() in exts:
                yield str(p), label

def load_image_rgb(path: str) -> Optional[np.ndarray]:
    try:
        img = Image.open(path).convert("RGB")
    except Exception:
        return None
    return np.array(img)  # RGB

def rgb_to_bgr(arr: np.ndarray) -> np.ndarray:
    return arr[:, :, ::-1]

def upsample_if_needed(img_rgb: np.ndarray) -> np.ndarray:
    h, w = img_rgb.shape[:2]
    m = min(h, w)
    if m >= UPSAMPLE_TARGET_MIN:
        return img_rgb
    scale = UPSAMPLE_TARGET_MIN / m
    new_w = int(round(w * scale))
    new_h = int(round(h * scale))
    return np.array(Image.fromarray(img_rgb).resize((new_w, new_h), Image.BICUBIC))

def get_embedding_direct(rec_model, img_rgb: np.ndarray) -> Optional[np.ndarray]:
    """Direkt embedding (bypass detektor). Resize ‚Üí 112x112."""
    if img_rgb is None:
        return None
    img_112 = Image.fromarray(img_rgb).resize((112, 112), Image.BICUBIC)
    bgr = rgb_to_bgr(np.array(img_112)).astype(np.uint8)
    emb = rec_model.get(bgr)
    if emb is None or emb.size == 0:
        return None
    return emb.astype(np.float32)


# ----------- Embedding-funktion -----------
def compute_embedding(app: FaceAnalysis,
                      rec_model,
                      img_path: str,
                      allow_fallback: bool,
                      allow_upsample: bool) -> tuple[Optional[np.ndarray], int, bool]:
    """
    Returnerar (embedding, antal_ansikten, fallback_anv√§ndes).

    Logik:
      1) Om bilden √§r < MIN_* -> om fallback till√•ts: direkt embedding, annars None.
      2) Detektera p√• original.
      3) Om 0 ansikten och allow_upsample: upsampla och detektera igen.
      4) Om fortfarande 0 och allow_fallback: direkt embedding.
      5) Acceptera endast exakt 1 ansikte (oavsett metod).
    """
    img_rgb = load_image_rgb(img_path)
    if img_rgb is None:
        return None, 0, False

    h, w = img_rgb.shape[:2]
    if w < MIN_WIDTH or h < MIN_HEIGHT:
        if allow_fallback:
            emb = get_embedding_direct(rec_model, img_rgb)
            return (emb, 1 if emb is not None else 0, True)
        return None, 0, False

    # 1) Detektera
    img_bgr = rgb_to_bgr(img_rgb)
    faces = app.get(img_bgr)
    n_faces = len(faces)

    # 2) Upsample
    if n_faces == 0 and allow_upsample:
        img_up = upsample_if_needed(img_rgb)
        if img_up is not img_rgb:
            faces = app.get(rgb_to_bgr(img_up))
            n_faces = len(faces)

    # 3) Fallback
    if n_faces == 0 and allow_fallback:
        emb = get_embedding_direct(rec_model, img_rgb)
        return (emb, 1 if emb is not None else 0, True)

    if n_faces != 1:
        return None, n_faces, False

    emb = faces[0].embedding
    if emb is None or emb.size == 0:
        return None, n_faces, False

    return emb.astype(np.float32), n_faces, False


# ----------------- Pipeline -----------------
def encode(args) -> None:
    data_root = Path(args.data_root)
    workdir   = Path(args.workdir)
    workdir.mkdir(parents=True, exist_ok=True)

    emb_path  = workdir / EMB_PKL
    proc_path = workdir / PROC_JSONL

    X, y = load_embeddings(emb_path)
    processed = load_processed(proc_path)

    all_imgs = list(iter_images(data_root))
    todo = [(p, lbl) for p, lbl in all_imgs if p not in processed]

    if not todo:
        print("‚úÖ Inget att g√∂ra ‚Äì allt √§r redan processat.")
        return

    print(f"üîç Att processa: {len(todo)} bilder (skippar {len(processed)})")

    app = init_app(["CPUExecutionProvider"])
    rec_model = app.models["recognition"]

    try:
        for path, label in tqdm(todo, unit="img"):
            ok = False
            try:
                emb, n, fb = compute_embedding(
                    app,
                    rec_model,
                    path,
                    allow_fallback=args.allow_fallback,
                    allow_upsample=args.allow_upsample
                )
                if emb is not None and n == 1:
                    X.append(emb)
                    y.append(label)
                    ok = True
            except Exception as e:
                print(f"‚ùå {path}: {e}", file=sys.stderr)

            append_processed(proc_path, path, ok)

            if ok and (len(X) % args.flush_every == 0):
                save_embeddings(emb_path, X, y)

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Avbrutet. Sparar state...")

    finally:
        save_embeddings(emb_path, X, y)
        print(f"üíæ Sparade embeddings ({len(X)}) till {emb_path}")


def train(args) -> None:
    workdir   = Path(args.workdir)
    emb_path  = workdir / EMB_PKL
    model_out = Path(args.model_out)

    X_list, y_list = load_embeddings(emb_path)
    if not X_list:
        print("‚ùå Inga embeddings ‚Äì k√∂r encode f√∂rst.")
        sys.exit(1)

    X = np.vstack(X_list)
    y = np.array(y_list)

    le = LabelEncoder()
    y_enc = le.fit_transform(y)

    counts = {cls: np.sum(y == cls) for cls in np.unique(y)}
    min_count = min(counts.values())
    k = 1 if min_count < args.min_per_class else args.k

    clf = KNeighborsClassifier(n_neighbors=k, weights="distance", metric="cosine")
    clf.fit(X, y_enc)

    with model_out.open("wb") as f:
        pickle.dump({"model": clf, "label_encoder": le}, f, protocol=pickle.HIGHEST_PROTOCOL)

    print(f"‚úÖ Modell sparad: {model_out} (k={k}, klasser={len(np.unique(y))})")


# ------------------ CLI ---------------------
def main():
    global EMB_PKL  # Flytta global-deklarationen hit

    ap = argparse.ArgumentParser(description="ArcFace-pipeline (progressbar + checkpoints, fallback & upsampling)")
    ap.add_argument("--data-root", default=DEFAULT_DATA_ROOT, help="Rotmapp med personmappar")
    ap.add_argument("--workdir",   default=DEFAULT_WORKDIR,   help="Arbetsmapp/checkpoints")
    ap.add_argument("--embeddings", default=EMB_PKL,          help="Fil med embeddings (.pkl)")  # Nytt argument
    ap.add_argument("--model-out", default=MODEL_PKL,         help="Filnamn f√∂r sparad modell (.pkl)")
    ap.add_argument("--mode", choices=["encode", "train", "both"], default="both")
    ap.add_argument("--flush-every", type=int, default=200, help="Spara embeddings var N:e lyckade bild")
    ap.add_argument("-k", type=int, default=K_DEFAULT, help="k f√∂r KNN")
    ap.add_argument("--min-per-class", type=int, default=MIN_PER_CLASS_DEF,
                    help="Om minsta klass < detta -> k=1")

    ap.add_argument("--allow-fallback", action="store_true",
                    help="Till√•t direkt embedding utan detektor om inga ansikten hittas")
    ap.add_argument("--allow-upsample", action="store_true",
                    help="Upsampla sm√• bilder innan ny detektionsk√∂rning")

    args = ap.parse_args()

    EMB_PKL = args.embeddings  # Uppdatera den globala variabeln

    if args.mode in ("encode", "both"):
        encode(args)
    if args.mode in ("train", "both"):
        train(args)

if __name__ == "__main__":
    main()
